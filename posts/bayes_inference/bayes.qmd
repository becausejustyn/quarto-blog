---
title: "Untitled"
execute: 
  freeze: true
  eval: false
format:
  html:
    highlight: true
    code-fold: show
    code-tools: true
    highlight-style: github
---

# Bayesian Inference

The main difference between Bayes Thereom and Bayesian Inference is that inference deals with probability distributions instead of point probabilities.

Bayes thereom in the context of statistical inference can be expressed like

$$
f(\theta | \text{Data}) = \frac{f(\text{Data} | \theta)f(\theta)}{f(\text{Data})}
$$

$$
f(\text{Data}) = \int f(\text{Data} | \theta)f(\theta) d \theta
$$

The only difference is that the integral takes continious values.

$$
\text{Posterior} \propto \text{Likelihood} \cdot \text{Prior}
$$

### Coin Flip Example

$$
\mathcal{L}(\theta | k) = \binom{n}{k} \theta^{k} (1 - \theta)^{n-k}
$$

```{python}
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import beta
from scipy import stats

plt.style.use("seaborn")
```

```{python}
x = np.linspace(0, 1, 100)
params = [(0.5, 0.5), (1, 1), (5, 3), (2, 5), (10, 10)]
colors = ["c-", "m-", "g-", "y", "r-"]

for p, c in zip(params, colors):
	y = beta.pdf(x, p[0], p[1])
	plt.plot(x, y, c, label="$\\alpha=%s$, $\\beta=%s$" % p)

plt.grid(True)
plt.xlabel("$\\theta$")
plt.ylabel("Density")
plt.title('Beta Distribution')
plt.legend()
plt.show()
```

```{python}
n_trials = [0, 1, 2, 4, 8, 16, 32, 64, 128, 500]
data = stats.bernoulli.rvs(0.5, size=n_trials[-1])
x = np.linspace(0, 1, 100)

plt.style.use("seaborn")

for i, n in enumerate(n_trials):
	heads = data[:n].sum()
	ax = plt.subplot(len(n_trials) / 2, 2, i + 1)
	plt.setp(ax.get_yticklabels(), visible=False)

	y = stats.beta.pdf(x, heads + 1, n - heads + 1)
	plt.plot(x, y, color="skyblue", label="%d tosses,\n %d heads" % (n, heads))
	plt.fill_between(x, 0, y, color="skyblue", alpha=0.5)
	plt.legend(loc=1)

plt.tight_layout()
plt.show()
```

```{python}

```

```{python}

```