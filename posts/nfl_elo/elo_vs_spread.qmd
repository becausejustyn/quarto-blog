---
title: "Untitled"
execute: 
  freeze: true
  eval: false
format:
  html:
    highlight: true
    code-fold: show
    code-tools: true
    highlight-style: github
---

```{python}
%matplotlib inline

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd  # at least 0.19.2 to read_csv from url
import seaborn as sns
import scipy.stats as stats
from collections import OrderedDict
# Ignore a future warning that comes from scipy.
import warnings
warnings.filterwarnings("ignore")

# Seaborn setup
sns.set_context("notebook")
sns.set_style("white")
```

```{python}
url = "https://github.com/fivethirtyeight/nfl-elo-game/raw/master/data/nfl_games.csv"
df = pd.read_csv(url)
print(df.shape)
df.head(5)
```

```{python}
# create the spread column. This is just point diff

df['spread'] = df.score1 - df.score2
print("Total teams in the dataset:", len(df.team1.unique()))
print("Total teams after 1990:", len(df[df.season > 1990].team1.unique()))
```

```{python}
def color_coded_hist(x, **kwargs):
    """Color the negative and positive bins differently.

    Color scheme from http://colorbrewer2.org/    
    """
    hist_bins = [-75, -42, -35, -28, -21, -14, -7, 0, 7, 14, 21, 28, 35, 42, 75]
    __, __, patches = plt.hist(x, density=True, bins=hist_bins, color="#f1a340")
    # Purple for positive spread:
    i = next(i for i, val in enumerate(hist_bins) if val == 0)
    for p in patches[i:]:
        p.set_facecolor("#998ec3")
        

def best_norm(x, **kwargs):
    """Plot the best normal fit for the data."""
    mu, std = stats.norm.fit(x)
    # Plot the PDF.
    xmin, xmax = min(x), max(x)
    x = np.linspace(xmin, xmax, 100)
    p = stats.norm.pdf(x, mu, std)
    plt.plot(x, p, 'k--', alpha = 0.6)
```

```{python}
# Plot all of the teams' spreads since 1990

g = sns.FacetGrid(
    df[df.season > 1990].sort_values('team1'), 
    col = "team1", col_wrap = 5, height = 2)

g = (g
.map(color_coded_hist, "spread")
.map(best_norm, "spread")
.set_titles("{col_name}")
.set_axis_labels("spread", "density"))

msg = "Histograms of spread (at home) since 1990. Normal approximation is dashed line."
plt.suptitle(msg, y = 1.025, fontsize = 14)
```

```{python}
# Show some of the values
print("~ Overall ~")

print(
    df[
        df.neutral == 0][
            ['spread', 'result1']].mean())

print("\n~ Past few seasons ~")

print(
    df[
        (df.neutral == 0) & 
        (df.season > 2011)
        ]
    .groupby("season")[["spread", "result1"]]
    .mean()
)
```

```{python}
# Create a data frame with lagged rolling means and combine with the existing data
rolling_avg = (
    df.groupby("season")[["spread", "result1"]]
    .mean()
    .rolling(3, min_periods = 1)
    .mean()
    .shift(1)
)

rolling_avg["win_pct_advantage"] = rolling_avg.result1 - 0.5
rolling_avg["spread_advantage"] = rolling_avg.spread
rolling_avg = rolling_avg.drop(columns = ["result1", "spread"])
```

```{python}
# Plot everything
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (14.0, 4.0)
f, ax = plt.subplots(1, 2)

sns.lineplot(x = "season", y = "spread", data = df[df.neutral == 0], ax = ax[0])
ax[0].plot(rolling_avg.index, rolling_avg.spread_advantage, 'k:')
ax[0].set_ylabel("home spread")

sns.lineplot(x = "season", y = "result1", data = df[df.neutral == 0], ax = ax[1])
ax[1].plot(rolling_avg.index, rolling_avg.win_pct_advantage + .5, 'k:')
ax[1].set_ylabel("home win percent")

plt.suptitle(
    'Central tendency and confidence interval of spread (left), '
    'win percent (right) by season â€” lagged moving average is dotted line',
    fontsize = 14)
```

```{python}
#Convert from game to team format

home_games = df[
    ["date", "season", "neutral", "playoff", "team1", "team2", "result1", "spread"]
][df.season > 1990]

home_games["home"] = 1

# Now swap the teams for "away"
away_games = home_games.rename(columns = {"team1": "team2", "team2": "team1"})
away_games["home"] = 1 - home_games.home

# Remember to switch the meaning of the winning and spread columns too
away_games["result1"] = 1 - home_games.result1
away_games["spread"] = -home_games.spread

by_team = pd.concat(
    [home_games, away_games], ignore_index = True).sort_values(
    by=["season", "team1", "date"]
)
```

```{python}
from abc import ABC, abstractmethod
from collections import namedtuple

class Updater(ABC):
    def __init__(self, *hyperparameters):
        # Form of lookup:
        # {season: {team: [{week1 data}, {week2 data}, ... {weekN data}]}}
        self.lookup = {}
        self.Params = namedtuple('Params', ['date'] + list(hyperparameters))
        
    def iterrows(self):
        for season, teams in self.lookup.items():
            for team, results in teams.items():
                for row in results:
                    yield dict(season=season, team1=team, **row._asdict())
        
    def get_rows(self):
        return [r for r in self.iterrows()]
    
    @abstractmethod
    def revert_to_mean(self, season, team, keep=.3, n_obs=8):
        pass
    
    @abstractmethod
    def update(self, row):
        pass
```

```{python}
class BernoulliUpdater(Updater):
    def __init__(self):
        super().__init__('alpha1', 'beta1')
        
    def revert_to_mean(self, season, team, keep=.8, n_obs=4):
        # default
        alpha = beta = 1 + n_obs * .5
        # or use existing data        
        if season in self.lookup and team in self.lookup[season]:
            last_entry = self.lookup[season][team].pop()
            date, alpha0, beta0 = last_entry
            p = alpha0 / (alpha0 + beta0)
            alpha = 1 + n_obs * (keep * p + (1 - keep) * .5)
            beta = 1 + n_obs * (keep * (1 - p) + (1 - keep) * .5)
            # push back the reverted value to the list
            self.lookup[season][team].append(self.Params(date, alpha, beta))
        return alpha, beta
            
    def update(self, row):
        if row.season not in self.lookup:
            self.lookup[row.season] = {}
        if row.team1 not in self.lookup[row.season]:
            self.lookup[row.season][row.team1] = []
            alpha, beta = self.revert_to_mean(row.season - 1, row.team1)
        else:
            __, alpha, beta = self.lookup[row.season][row.team1][-1]
        # THE UPDATE STEP:
        # a' = a + 1 if win else 0
        # b' = b + 1 if lose
        if row.result1 == 1:  # Won
            alpha_beta_next = self.Params(row.date, alpha + 1, beta)
        elif row.result1 == 0.5:  # Tie
            alpha_beta_next = self.Params(row.date, alpha + .5, beta + .5)
        else:  # Lost
            alpha_beta_next = self.Params(row.date, alpha, beta + 1)
        self.lookup[row.season][row.team1].append(alpha_beta_next)
        return alpha, beta


bernoulli_updater = BernoulliUpdater()
for i, row in by_team.iterrows():
    bernoulli_updater.update(row)

ab = pd.DataFrame(bernoulli_updater.get_rows()).sort_values(['team1','season'])
g = ab.groupby('team1')
ab = ab.assign(alpha1 = g.alpha1.shift(), beta1=g.beta1.shift())

bernoulli_dataset = (
    by_team[[c for c in by_team.columns if c != 'spread']]
    .merge(ab, on=['season', 'date', 'team1'])
    .reindex(columns=[
        'season', 'date', 'home', 'neutral', 'playoff',
        'team1', 'team2', 'result1', 'alpha1', 'beta1'])
)
```

```{python}
bernoulli_dataset[(bernoulli_dataset.season == 1993) & (bernoulli_dataset.team1 == 'PHI')]
```

```{python}
#Convert back from "by-team" to "by-game" format

b = (
    bernoulli_dataset[['season', 'date', 'team1', 'alpha1', 'beta1']]
    .rename(columns=dict(team1='team2', alpha1='alpha2', beta1='beta2'))
    .merge(bernoulli_dataset, on=['season', 'date', 'team2'])
    .join(
        rolling_avg[['win_pct_advantage']]
        .rename(columns={'win_pct_advantage':'home_advantage'})
        , on='season')
)

b = (
    b.assign(
        pwin = 
        (b.alpha1 + b.beta2 - 1) / (b.alpha1 + b.beta1 + b.alpha2 + b.beta2 - 2)
        # if at home and not neutral add home advantage
        + b.home * (1 - b.neutral) * b.home_advantage
        # if away and not neutral subtract home advantage
        - (1 - b.home) * (1 - b.neutral) * b.home_advantage
        ,
        success = lambda row:  row.pwin.round() == row.result1
    )
    .reindex(columns=(
        list(bernoulli_dataset.columns)
        + ['alpha2', 'beta2', 'home_advantage', 'pwin', 'success']
    ))
)

print(b.success.mean())
b.tail()
```

```{python}
def plot_roc(predicted, actual, resolution=100, ax=None):
    """'predicted' and 'actual' are pandas Series."""
    ax = ax or plt.gca()
    cutoff = np.linspace(0, 1, resolution)
    total_pos = (actual == 1).sum()
    total_neg = (actual != 1).sum()
    true_positive_rate = np.fromiter(
        map(lambda c: (actual[predicted > c] == 1).sum() / total_pos, cutoff),
        float)
    false_positive_rate = np.fromiter(
        map(lambda c: (actual[predicted > c] != 1).sum() / total_neg, cutoff),
        float)
    ax.plot(
        false_positive_rate, true_positive_rate,
        linestyle='-', color=sns.color_palette()[0], linewidth=3)
    ax.set_xlim([0,1])
    ax.set_ylim([0,1])
    ax.plot([0,1], [0,1], 'k:')
    # Area under the curve
    auc = sum((true_positive_rate[:-1] + true_positive_rate[1:]) / 2
              * (false_positive_rate[:-1] - false_positive_rate[1:]))
    ax.set_title('ROC curve. AUC = {:0.3f}'.format(auc), fontsize=14);


## Start the actual plot
plt.rcParams['figure.figsize'] = (15.0, 3.0)
f, ax = plt.subplots(1, 3)

summary = b.groupby(['team1', 'season'], as_index=False).success.mean()

# Histogram
sns.distplot(summary.success, ax=ax[0], bins=np.linspace(0, 1, 11))
ax[0].axvline(0.5, color='k', linestyle=':')
ax[0].set_ylabel("frequency count")
ax[0].set_title('Model accuracy (grouped by team, season)', fontsize=14)

# Time series
sns.lineplot(x="season", y="success", data=summary, ax=ax[1])
ax[1].set_ylabel("Model success rate")
ax[1].set_title('Accuracy year over year (mean {:0.0%})'.format(b.success.mean()), fontsize=14)

# ROC
plot_roc(b.pwin, b.result1, resolution=100, ax=ax[2])
```

```{python}
class TUpdater(Updater):
    def __init__(self):
        super().__init__('nu1', 'mu1', 'alpha1', 'beta1')
        
    def get_mean_beta(self, season):
        mean_beta = 16**2 / 2  # Default
        if season in self.lookup:
            team_sets = self.lookup[season].values()
            mean_beta = (
                sum(ts[-1].beta1 for ts in team_sets)
                / sum(ts[-1].nu1 for ts in team_sets))
        return mean_beta
        
    def revert_to_mean(self, season, team, keep=.5, n_obs=3):
        mean_beta = self.get_mean_beta(season - 1)  # Default
        nu, mu, alpha, beta = n_obs, 0, n_obs / 2, mean_beta * n_obs
        # or use existing data
        if season in self.lookup and team in self.lookup[season]:
            last_entry = self.lookup[season][team].pop()
            date, nu0, mu0, alpha0, beta0 = last_entry
            mu = keep * mu0
            beta = nu * (keep * beta0 / nu0 + (1 - keep) * mean_beta)
            # push back the reverted value to the list
            self.lookup[season][team].append(self.Params(date, nu, mu, alpha, beta))
        return nu, mu, alpha, beta
            
    def update(self, row):
        if row.season not in self.lookup:
            self.lookup[row.season] = {}
        if row.team1 not in self.lookup[row.season]:
            self.lookup[row.season][row.team1] = []
            nu, mu, alpha, beta = self.revert_to_mean(row.season - 1, row.team1)
        else:
            __, nu, mu, alpha, beta = self.lookup[row.season][row.team1][-1]
        # THE UPDATE STEP:
        delta = row.spread - mu
        nu_mu_alpha_beta_next = self.Params(
            row.date,
            nu + 1,                       # nu' = nu + 1
            mu + delta / (nu + 1),        # mu' = mu + delta / (nu + 1)
            alpha + .5,                   # alpha' = alpha + 1/2
            beta + delta * (mu + delta / (nu + 1)) / 2
                                          # beta' = beta + delta * mu' / 2
        )
        self.lookup[row.season][row.team1].append(nu_mu_alpha_beta_next)
        return nu, mu, alpha, beta


t_updater = TUpdater()
for i, row in by_team.iterrows():
    t_updater.update(row)

nmab = pd.DataFrame(t_updater.get_rows()).sort_values(['team1','season'])
g = nmab.groupby('team1')
nmab = nmab.assign(
    nu1 = g.nu1.shift(),
    mu1 = g.mu1.shift(),
    alpha1 = g.alpha1.shift(),
    beta1=g.beta1.shift())

t_dataset = (
    by_team[[c for c in by_team.columns if c != 'result1']]
    .merge(nmab, on=['season', 'date', 'team1'])
    .reindex(columns=[
        'season', 'date', 'home', 'neutral', 'playoff',
        'team1', 'team2', 'spread', 'nu1', 'mu1', 'alpha1', 'beta1'])
)
```

```{python}
t_dataset[(t_dataset.season == 2017) & (t_dataset.team1 == 'PHI')]
```

```{python}
t = (
    t_dataset[['season', 'date', 'team1', 'nu1', 'mu1', 'alpha1', 'beta1']]
    .rename(columns=dict(
        team1='team2', nu1='nu2', mu1='mu2', alpha1='alpha2', beta1='beta2'))
    .merge(t_dataset, on=['season', 'date', 'team2'])
    .join(
        rolling_avg[['spread_advantage']]
        .rename(columns={'spread_advantage':'home_advantage'})
        , on='season')
)

t = (
    t.assign(
        pspread =
            (t.nu1 * t.mu1 - t.nu2 * t.mu2) / (t.nu1 + t.nu2)
            # if at home and not neutral add home advantage
            + t.home * (1 - t.neutral) * t.home_advantage
            # if away and not neutral subtract home advantage
            - (1 - t.home) * (1 - t.neutral) * t.home_advantage
        ,
        betaprime =
            t.beta1 + t.beta2
            + (t.nu1 * t.nu2) / (t.nu1 + t.nu2)
            * (t.mu1 + t.mu2)**2 / 2
        ,
        pwin = (
            lambda row: 1 - stats.t.cdf(
                0,
                row.nu1 + row.nu2,
                loc=row.pspread,
                scale=(
                    row.betaprime
                    * (row.nu1 + row.nu2 + 1)
                    / (row.nu1 + row.nu2) / (row.alpha1 + row.alpha2)
                )))
        ,
        success = lambda row: row.pwin.round() == (row.spread > 0)
    )
    .reindex(columns=(
        list(t_dataset.columns)
        + ['nu2', 'mu2', 'alpha2', 'beta2', 'home_advantage', 'pspread', 'pwin', 'success']
    ))
)

print(t.success.mean())
print(t.shape)
t.tail()
```

```{python}
# use toggle
ss_res = ((t.spread - t.pspread)**2).sum()
ss_tot = ((t.spread - t.spread.mean())**2).sum()
r_squared = 1 -  ss_res/ ss_tot
sns.jointplot("spread", "pspread", data=t, kind="hex", space=0, color="b", ratio=4)
title = "Actual spread vs. mean of  distribution. R squared= {:0.0%}".format(r_squared)
plt.suptitle(title, x=.45, y=1.01, fontsize=14)
```

```{python}
# use toggle
plt.rcParams['figure.figsize'] = (15.0, 3.0)
f, ax = plt.subplots(1, 3)

summary = t.groupby(['team1', 'season'], as_index=False).success.mean()

# Histogram
sns.distplot(summary.success, ax=ax[0], bins=np.linspace(0, 1, 11))
ax[0].axvline(0.5, color='k', linestyle=':')
ax[0].set_ylabel("frequency count")
ax[0].set_title('Model accuracy (grouped by team, season)', fontsize=14)

# Time series
sns.lineplot(x="season", y="success", data=summary, ax=ax[1])
ax[1].set_ylabel("Model success rate")
ax[1].set_title('Accuracy year over year (mean {:0.0%})'.format(t.success.mean()), fontsize=14)

# ROC
plot_roc(t.pwin, t.spread > 0, resolution=100, ax=ax[2])
```

