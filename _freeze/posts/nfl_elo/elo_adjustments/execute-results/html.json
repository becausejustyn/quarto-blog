{
  "hash": "f4a24e83d426394bafafa42a8817cb99",
  "result": {
    "markdown": "---\ntitle: \"Untitled\"\nexecute: \n  freeze: true\n  eval: false\nformat:\n  html:\n    highlight: true\n    code-fold: show\n    code-tools: true\n    highlight-style: github\n---\n\n\n# ELO Adjustments\n\n\n$$\n\\underbrace{Elo}_{\\text{current year}} = \\underbrace{Elo}_{\\text{previous year}} \\times \\frac{2}{3} + 1500 \\times \\frac{1}{3}\n$$\n\n\nYou could also use a 4 year rolling mean since the average career is 3.5 years. However, the average player would not make as much difference as key players.\n\nAdditionally, if you want to value margin of victory that discounts blowouts, e.g. winning by 21 points is not much better than winning by 28\n\n\n$$\n\\text{Margin of Victory Multiplier} = ln(|\\text{PointDiff}| +1) \\times \\frac{2.2}{|\\underbrace{Elo}_{\\text{A}} - \\underbrace{Elo}_{\\text{B}}| \\times 0.001 + 2.2}\n$$\n\n\nIf you want to include turnover and yard differential you could do\n\nMargin of Victory, Turnover, Yard, Differential Multiplier = MM\n\n\n$$\n\\text{MM} = e^{(\\frac{1}{5}(\\text{Turnover Diff}))} \\times \\text{ ln } (| \\text{PointDiff} | +1) \\times \\frac{2.2}{(|\\underbrace{Elo}_{\\text{A}} - \\underbrace{Elo}_{\\text{B}}| \\times 0.001 + 2.2)}\n$$\n\n\n\n\n`http://schw4rzr0tg0ld.s3-website.eu-central-1.amazonaws.com/blog/2018/08/elo-boosting.html`\n\nThe ELO model uses a scaled logistic function to map differences in strength to probabilities of won and loss. Let $Team_{A}$ be the elo rating for $Team_{A}$, and $Team_{B}$ for $Team_{B}$, and $y_{i} = 1$ if $Team_{A}$ wins, 0.5 if they draw, and 0 if they lose.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncalculate_predictor <- function(X, beta) {\n  # calculate the linear predictor Xbeta\n  colSums(t(X) * beta)\n}\n\nlogistic_function <- function(predictor, scaling_factor = log(10)/400) {\n  # ELO uses a scaling factor compared of log(10) / 400 compared to the\n  # usual specification\n  1 / (1 + exp(-predictor * scaling_factor))\n}\n\nlogistic_loss <- function(X, y, beta) {\n  # number of observations\n  N <- length(y)\n  # expected score, i.e. predicted probability for win/loss\n  e_score <- logistic_function(calculate_predictor(X, beta))\n\n  loss <- (1 / N) * sum(-y * log(e_score) - (1 - y) * log(1 - e_score))\n  return(loss)\n}\n\nupdate_beta <- function(X, y, beta, k) {\n  # number of observations\n  n <- length(y)\n  # expected score, i.e. predicted probability for win/loss\n  e_score <- logistic_function(calculate_predictor(X, beta))\n  # gradient and the current position\n  gradient <- colSums(X * (e_score - y))\n  # update step\n  beta <- beta - k * gradient\n  # print logistic loss\n  #print(logistic_loss(X, y, beta))\n  return(beta)\n}\n\ngradient_descent <- function(batches, beta_init, k, iterations) {\n  # set beta to initial value\n  beta <- beta_init\n  # initalize matrix to store updates\n  beta_history <- matrix(nrow = length(batches),\n                         ncol = length(beta_init))\n  # loop over iterations, aka epochs\n  for (i in 1:iterations) {\n    # loop over mini-batches\n    for (b in 1:length(batches)) {\n      # run update procedure\n      batch <- batches[[b]]\n      beta <- update_beta(batch$X, batch$y, beta, k)\n      beta_history[b, ] <- beta\n    }\n  }\n  return(beta_history)\n}\n```\n:::\n\n\n### A Simple Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data.frame(\n  t = factor(c(0, 0, 0, 0, 1, 1, 1)),  # period\n  f = factor(c(1, 2, 3, 1, 2, 3, 3)),  # first team\n  s = factor(c(2, 3, 1, 3, 3, 1, 1)),  # second team\n  y = c(1, 1, 0, 1, 1, 0, 1) # win/loss\n  )  \n  \nget_input_variables <- function(data) {\n  design_matrix <-\n    model.matrix(~ as.factor(f) - 1, data) -\n    model.matrix(~ as.factor(s) - 1, data)\n  colnames(design_matrix) <- paste0(\"player_\", seq_len(ncol(design_matrix)))\n  return(list(X = design_matrix, y = data$y))\n}\n\nbatches <- lapply(split(data, data$t), get_input_variables)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# determine numer of players from data\nP <- max(sapply(batches, function(x) {ncol(x$X)}))\n# run batch gradient descent\nbgd_beta <- gradient_descent(batches, \n                             beta = numeric(P), \n                             k = 1,\n                             iterations = 1)\n# formatting\nbgd_beta_df <- data.frame(bgd_beta)\ncolnames(bgd_beta_df) <- paste0(\"beta_\", seq_len(P))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nelo_ratings <- PlayerRatings::elo(data.frame(apply(data, 2, as.numeric)),\n                                  kfac = 1, init = 0, history = TRUE)\n# formatting\nelo_ratings_df <- data.frame(t(elo_ratings$history[, , \"Rating\"]))\ncolnames(elo_ratings_df) <- paste0(\"beta_\", seq_len(P))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata$t <- factor(0)\n# via glm\nsingle_batch <- get_input_variables(data)\nX <- single_batch$X[, -1]  # drop first player for identification\ny <- single_batch$y\nglm_beta <- c(0, coef(glm(y~ -1 + X, family = binomial)))\nglm_beta <- glm_beta * 400 / log(10)  # normalizing factor from ELO\n\n# formatting\nglm_beta_df <- data.frame(t(glm_beta))\ncolnames(glm_beta_df) <- paste0(\"beta_\", seq_len(P))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbgd_beta_opt <- gradient_descent(list(single_batch), \n                             beta = numeric(P), \n                             k = 1,\n                             iterations = 1000)\n\n# normalize btea_1 to zero\nbgd_beta_opt <- bgd_beta_opt - bgd_beta_opt[1, 1]\n# formatting\nbgd_beta_opt_df <- data.frame(bgd_beta_opt)\ncolnames(bgd_beta_opt_df) <- paste0(\"beta_\", seq_len(P))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# for ELO\nELO_beta <- gradient_descent(list(single_batch), \n                             beta = numeric(P), \n                             k = 1,\n                             iterations = 1)\nlogistic_loss(single_batch$X, single_batch$y, as.numeric(ELO_beta))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# for GLM\nGLM_beta <- gradient_descent(list(single_batch), \n                             beta = numeric(P), \n                             k = 1,\n                             iterations = 1000)\nlogistic_loss(single_batch$X, single_batch$y, as.numeric(GLM_beta))\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}