{
  "hash": "fe7c37219e9ed9c0ccb59b3f537cc95c",
  "result": {
    "markdown": "---\ntitle: \"Untitled\"\nexecute: \n  freeze: true\n  eval: false\nformat:\n  html:\n    highlight: true\n    code-fold: show\n    code-tools: true\n    highlight-style: github\n---\n\n## NFL ELO\n\n`https://andr3w321.com/a-note-on-autocorrelation/`\n`https://fivethirtyeight.com/methodology/how-our-nfl-predictions-work/`\n\n## Elo functions\n\n\n```{none}\n#yearly_adjustment\n\nelo_current_year = (elo_previous_year * 2/3) + (1500 * 1/3)\n\n#margin of victory\n```\n\n$$\\text{Margin of Victory Multiplier} = ln(\\text{WinnerPointDiff} + 1) \\times \\frac{2.2}{\\text{WinnerEloDiff} \\times 0.001 + 2.2}$$\n\n\n\n$\\text{Margin of Victory Multiplier} = LN(ABS(\\text{Point Diff})+1) \\times \\left( \\frac{2.2}{((ELOW-ELOL)*.001+2.2)} \\right)$\n\nWhere PD is the point differential in the game, ELOW is the winning team’s Elo Rating before the game, and ELOL is the losing team’s Elo Rating before the game.\n\n`margin_of_victory = log(winner_point_diff + 1) * (2.2 / winner_elo_diff * 0.001 + 2.2)`\n\n\n# Elo and Logistic Regression\n\n\n\n\n$$\n\\Large \\text{Expected Score} = \\frac{1}{10^{\\frac{(Team_{B} - Team_{A})}{\\text{Scaling Factor}}}+1}\n$$\n\n\nInstead of the typical $log_{e}$ odds, Arpad Elo used $log_{10}$ hence the `10` in the formula.\n\nOdds is the probability an event happens divided by the probability that it does not happen, e.g. 4:1 odds imply an 80% chance of an event occuring (0.8/0.2 = 4). Thus, the log odds is\n\n\n$$\n\\Large a = \\log \\frac{\\text{P }(\\mathbf{x} \\; | \\; y=1)\\text{ P }(y=1)}{\\text{P }(\\mathbf{x} \\;|\\; y=0)\\text{ P }(y=0)}\n$$\n\n\nNote: here we are using $log_{e}$\n\nUsing Bayes, we get\n\n\n$$\n\\Large \\begin{align*}\nP(y = 1 \\; |\\; \\mathbf{x}) &= \\frac{P(\\mathbf{x}\\;|\\; y = 1)P(y = 1)}{\\sum_{k} P(\\mathbf{x}\\;|\\; y = k)P(y = k)} \\\\\n&= \\frac{1}{1+\\frac{P(\\mathbf{x}\\;|\\; y \\;=\\; 0)P(y \\;=\\; 0)}{P(\\mathbf{x}\\;|\\; y \\;= \\;1)P(y \\;=\\; 1)}} \\\\\n&= \\frac{1}{1+e^{-a}}\n\\end{align*} \n$$\n\n\nIf we assume the conditional densities are normal with a shared covariance matrix and equally likely classes, then\n\n\n$$\n\\Large \\text{Pr}(y=1\\;| \\;\\mathbf{x}; \\mathbf{w}) = \\sigma(\\mathbf{w}^T \\mathbf{x})\n$$\n\n\nfor some `weight` vector $\\mathbf{w}$. With the data likelihood\n\n\n$$\n\\Large \\text{P}(\\text{Data}\\;|\\;\\mathbf{w}) = \\prod_{i=1}^{N} \\sigma^{y_{i}} (1-\\sigma)^{1-y_{i}}\n$$\n\n\nThen we want the negative log likelihood\n\n\n$$\n\\Large -\\log \\; \\text{Pr}(\\text{Data}\\;|\\;\\mathbf{w}) = -\\sum_{i=1}^{N} y_{i} \\; \\ln \\; \\sigma + (1-y_{i}) \\; \\ln \\; (1-\\sigma)\n$$\n\n\n### Stochastic Gradient Descent\n\nGradient descent simply is the technique of searching for a minumum by taking small steps towards the negative gradient:\n\n\n$$\n\\Large \\begin{equation}\n\\mathbf{w}_{k+1} = \\mathbf{w}_{k} - \\alpha \\ \\nabla E(\\mathbf{w}_{k})\n\\end{equation}\n$$\n\n\nWhere\n\n- $\\alpha$ influences how fast the update our estimate of $\\mathbf{w}$.\n- You are able to evaluate the gradient at **one** of the terms in the sum, then move in that direction, and you will likely reach a minimum, so long as you keep picking random terms and you do it enough times!  \n    - I find this really cool!\n- The `stochastic` comes from the random aspect. \n- It comes into play for logistic regression as such\n\n\n$$\n\\Large \\mathbf{w}_{k \\; + \\; 1} = \\mathbf{w}_{k} - \\alpha\\left( \\sigma \\; (\\mathbf{w}_{k^T} \\; \\mathbf{x}_{i}) - t_{i} \\right) \\; \\mathbf{x}_{i}\n$$\n\n\nor\n\n\n$$\n\\begin{equation}\n\\Large \\mathbf{w}_{k \\; + \\; 1} = \\mathbf{w}_{k} - \\alpha\\left( \\sigma \\; (\\mathbf{w}_{k^T} \\; \\mathbf{x}_{i}) - t_{i} \\right) \\; \\mathbf{x}_{i}\n\\end{equation}\n$$\n\n\n### NFL Example\n\nThe `weight` vector $\\mathbf{w}$ is now the ratings of all 32 teams.  Let's denote a specific game between teams $Team_{A}$ and $Team_{B}$ as the datapoint $\\big(\\mathbf{x}_{(Team_{A}, Team_{B})} \\; , \\; y_{(Team_{A}, Team_{B})}\\big)$, where:\n\n\n$$\n\\Large \\mathbf{x}_{(Team_{A} \\; Team_{B})} = [x_k] = \\begin{cases}\n1 & k = Team_{A} \\\\\n-1 & k = Team_{B} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\n\n\nand $y \\; {(Team_{A} \\; Team_{B})} = 1$ if $Team_{A}$ wins, 0 if $Team_{B}$ wins.  The class conditional probability of $Team_{A}$ winning is then\n\n\n$$\n\\large P \\Big( y \\; {\\big(Team_{A} \\; Team_{B}\\big)} = 1 \\; | \\; \\mathbf{x}{\\big(Team_{A} \\; Team_{B}\\big)}; \\; \\mathbf{w}\\Big) = \\sigma\\Big(\\mathbf{w}^T \\; \\mathbf{x}{\\big(Team_{A} \\; Team_{B}\\big)} \\Big)\n$$\n\n\nsince $\\mathbf{w}^{T} \\mathbf{x}_{(Team_{A} \\; Team_{B})} = w_{Team_{A}} - w_{Team_{B}}$ or in Elo notation, $\\text{elo}_{Team_{A}} - \\text{elo}_{Team_{B}}$.  Then given some initial estimate of the weight vector $\\mathbf{w}_{0}$, we can hone our estimate of the `weights` by iteratively applying an SGD step on the data,\n\n\n$$\n\\Large \\mathbf{w}_{k+1} = \\mathbf{w}_{k} - \\alpha \\ \\Big(\\sigma \\big(\\mathbf{w}_k^T \\; \\mathbf{x}{(Team_{A} \\; Team_{B})}\\big) - 1\\Big) \\; \\mathbf{x} {(Team_{A} \\; Team_{B})}\n$$\n\n\nor if we want to get gritty\n\n\n$$\n\\large \\begin{bmatrix} \nw_{1} \\\\ \n\\dots \\\\ \nw_{Team_{A}} \\\\ \nw_{Team_{B}} \\\\ \n\\dots \\\\ \nw_{N} \n\\end{bmatrix}_{k+1} = \\begin{bmatrix} \nw_{1} \\\\ \n\\dots \\\\ \nw_{Team_{A}} \\\\ \nw_{Team_{B}} \\\\ \n\\dots \\\\ \nw_{N}  \n\\end{bmatrix}_{k} + \\alpha \\left(1 - \\frac{1}{1+e^{-\\Big(w_{Team_{A}} - w_{Team_{B}}\\Big)}}\\right) \n\\begin{bmatrix} \n0 \\\\ \n\\dots \\\\ \n1 \\\\ \n-1 \\\\ \n\\dots \\\\ \n0 \\end{bmatrix}\n$$\n\n\n\n\n- The only two lines where anything's going on out of this update correspond to the two Elo update equations for a game up.  \n- Lots of signs flipping back and forth, and don't forget $\\sigma(-a)=1-\\sigma(a)$, but they're the same!  \n\n> From a high level, `Elo` ratings are actually `weights` of a **logistic regression** to predict pairwise game outcomes, which we learn through SGD-like updates over streaming data.\n\n`https://stmorse.github.io/journal/Elo.html`\n\nA common improvement to first order methods like GD/SGD is incorporation of **momentum**. (Here's a [beautiful Distill.pub article](https://distill.pub/2017/momentum/) about it.)  A simple example is the following modified gradient step:\n\n",
    "supporting": [
      "elo_notes_files"
    ],
    "filters": [],
    "includes": {}
  }
}